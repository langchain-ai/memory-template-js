{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6903df-d580-4988-a412-29acbe5a997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import ell\n",
    "\n",
    "\n",
    "@ell.simple(model=\"gpt-4o-mini\", temperature=1.0, n=10)\n",
    "def write_ten_drafts(idea: str):\n",
    "    \"\"\"You are an adept story writer. The story should only be 3 paragraphs\"\"\"\n",
    "    return f\"Write a story about {idea}.\"\n",
    "\n",
    "\n",
    "@ell.simple(model=\"gpt-4o\", temperature=0.1)\n",
    "def choose_the_best_draft(drafts: List[str]):\n",
    "    \"\"\"You are an expert fiction editor.\"\"\"\n",
    "    return f\"Choose the best draft from the following list: {'\\n'.join(drafts)}.\"\n",
    "\n",
    "\n",
    "drafts = write_ten_drafts(idea)\n",
    "\n",
    "best_draft = choose_the_best_draft(drafts)  # Best of 10 sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc5e407-5498-417d-8643-b049eef0af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6791557-dfdd-489c-a8c7-7f1884cd9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple(**dec_kwargs):\n",
    "    def decorator(fn):\n",
    "        model, msgs = (init_chat_model(**dec_kwargs),[(\"system\", getattr(fn, \"__doc__\"))] if getattr(fn, \"__doc__\") else [],)\n",
    "        def call(*args, **kwargs):\n",
    "            return model.invoke([*msgs, (\"user\", str(fn(*args, **kwargs)))]).content\n",
    "        return call\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20961e-1715-4d80-a231-abcd61dccece",
   "metadata": {},
   "outputs": [],
   "source": [
    "@simple(model=\"gpt-4o-mini\", temperature=1.0, n=10)\n",
    "def write_ten_drafts(idea: str):\n",
    "    \"\"\"You are an adept story writer. The story should only be 3 paragraphs\"\"\"\n",
    "    return f\"Write a story about {idea}.\"\n",
    "@simple(model=\"gpt-4o-mini\")\n",
    "def choose_the_best_draft(drafts: list[str]):\n",
    "    \"\"\"You are an expert fiction editor.\"\"\"\n",
    "    return f\"Choose the best draft from the following list: {drafts}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cb3f496-4054-4081-b7ca-039f80b34557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# def _get_inputs(signature, *args, **kwargs):\n",
    "#     \"\"\"Return a dictionary of inputs from the function signature.\"\"\"\n",
    "#     bound = signature.bind_partial(*args, **kwargs)\n",
    "#     bound.apply_defaults()\n",
    "#     arguments = dict(bound.arguments)\n",
    "#     arguments.pop(\"self\", None)\n",
    "#     arguments.pop(\"cls\", None)\n",
    "#     for param_name, param in signature.parameters.items():\n",
    "#         if param.kind == inspect.Parameter.VAR_KEYWORD:\n",
    "#             # Update with the **kwargs, and remove the original entry\n",
    "#             # This is to help flatten out keyword arguments\n",
    "#             if param_name in arguments:\n",
    "#                 arguments.update(arguments[param_name])\n",
    "#                 arguments.pop(param_name)\n",
    "\n",
    "#     return arguments\n",
    "\n",
    "\n",
    "# def _get_inputs_safe(signature, *args, **kwargs):\n",
    "#     try:\n",
    "#         return _get_inputs(signature, *args, **kwargs)\n",
    "#     except BaseException as e:\n",
    "#         print(e)\n",
    "#         return {\"args\": args, \"kwargs\": kwargs}\n",
    "\n",
    "\n",
    "def simple(**dec_kwargs):\n",
    "    def decorator(fn):\n",
    "        sysprompt = getattr(fn, \"__doc__\", \"\")\n",
    "        # sig = inspect.signature(fn)\n",
    "        model = init_chat_model(**dec_kwargs)\n",
    "        # agent = create_react_agent(model, [fn])\n",
    "\n",
    "        def call(*args, **kwargs):\n",
    "            # agent_args = _get_inputs_safe(sig, *args, **kwargs)\n",
    "            resp = fn(*args, **kwargs)\n",
    "            return model.invoke([(\"system\", sysprompt), (\"user\", str(resp))]).content\n",
    "\n",
    "        return call\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24ef9043-ff1a-4454-9e6d-c86a2655e2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32a36963-4cd0-476f-903a-064cea9330eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bed51da2-a920-4971-bbae-d84ce99cf884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The phrase \"once upon a time\" is the better draft. It evokes a sense of storytelling and invites the reader into a narrative, while \"I like pie\" is more of a simple statement without much context or depth. \"Once upon a time\" has the potential to lead into a rich and engaging story.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56237a71-3446-43d5-bb2e-6cbc0ddf7364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
